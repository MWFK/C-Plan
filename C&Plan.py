# -*- coding: utf-8 -*-
"""travexx.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bEikA2TVVk2QqAAUHXfE34K-YMigt05n
"""

import os
import zipfile
import random
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from shutil import copyfile

# Delete the content of the folder
!rm -rf /tmp/ny-v-tn

# Create a directory
os.mkdir('/tmp')

# Upload file 

# from google.colab import files
# uploaded = files.upload()

# Upload the file manually, then do this

local_zip = '/tmp/ny-v-tn.zip'
zip_ref   = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

# Create a directory for images

try:
    os.mkdir('/tmp/ny-v-tn')
    os.mkdir('/tmp/ny-v-tn/training')
    os.mkdir('/tmp/ny-v-tn/testing')
    os.mkdir('/tmp/ny-v-tn/training/tn')
    os.mkdir('/tmp/ny-v-tn/training/ny')
    os.mkdir('/tmp/ny-v-tn/testing/tn')
    os.mkdir('/tmp/ny-v-tn/testing/ny')
except OSError:
    pass

print(len(os.listdir('/tmp/ny-v-tn/training/tn/')))
print(len(os.listdir('/tmp/ny-v-tn/training/ny/')))
print(len(os.listdir('/tmp/ny-v-tn/testing/tn/')))
print(len(os.listdir('/tmp/ny-v-tn/testing/ny/')))

# Expected output:
# 15
# 15
# 5
# 5

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(255, 255, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])

TRAINING_DIR = "/tmp/ny-v-tn/training/"
train_datagen = ImageDataGenerator(rescale=1.0/255.)
train_generator = train_datagen.flow_from_directory(TRAINING_DIR,
                                                    batch_size=100,
                                                    class_mode='binary',
                                                    target_size=(255, 255))

VALIDATION_DIR = "/tmp/ny-v-tn/testing/"
validation_datagen = ImageDataGenerator(rescale=1.0/255.)
validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,
                                                              batch_size=100,
                                                              class_mode='binary',
                                                              target_size=(255, 255))

# Expected Output:
# Found 30 images belonging to 2 classes.
# Found 10 images belonging to 2 classes.

# Note that this may take some time.
history = model.fit_generator(train_generator,
                              epochs=10,
                              verbose=1,
                              validation_data=validation_generator)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib.image  as mpimg
import matplotlib.pyplot as plt

#-----------------------------------------------------------
# Retrieve a list of list results on training and test data
# sets for each training epoch
#-----------------------------------------------------------
acc=history.history['acc']
val_acc=history.history['val_acc']
loss=history.history['loss']
val_loss=history.history['val_loss']

epochs=range(len(acc)) # Get number of epochs

#------------------------------------------------
# Plot training and validation accuracy per epoch
#------------------------------------------------
plt.plot(epochs, acc, 'r', "Training Accuracy")
plt.plot(epochs, val_acc, 'b', "Validation Accuracy")
plt.title('Training and validation accuracy')
plt.figure()

#------------------------------------------------
# Plot training and validation loss per epoch
#------------------------------------------------
plt.plot(epochs, loss, 'r', "Training Loss")
plt.plot(epochs, val_loss, 'b', "Validation Loss")
plt.figure()

# Upload pictures to detect the city.

import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = '/content/' + fn
  img = image.load_img(path, target_size=(255, 255))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(classes[0])
  if classes[0]>0.5:
    print(fn + " This place looks like Tataouine")
  else:
    print(fn + " This place looks like New York")

